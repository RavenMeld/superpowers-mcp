# python-data-polars-duckdb

Practical data engineering workflows with Polars + DuckDB: fast local analytics, Parquet, and repeatable ETL patterns.

## Quick Facts
- id: `python-data-polars-duckdb--114e4a2ece`
- worth_using_score: `65/100`
- tags: `python, sql, ci, rag`
- source: `agent_playground`
- source_path: `/home/wolvend/codex/agent_playground/projects/awesome-skills-database/skillpacks/ravenmeld/python-data-polars-duckdb/SKILL.md`

## Use When
- You want fast local analytics without spinning up a database.
- You work with Parquet/CSV/JSON and need reliable transforms.
- You want a repeatable ETL pattern that scales from laptop to server.

## Workflow / Steps
- Use Polars for dataframe transforms (fast + memory-efficient).
- Use DuckDB for SQL over files (Parquet/CSV) and joins/aggregations.
- Persist intermediate results to Parquet (columnar, compressible, portable).
- Validate with small invariants (row counts, null rates, schema checks).

## Signal Summary
- has_description: `True`
- has_use_when: `True`
- has_workflow: `True`
- code_examples: `4`
- has_scripts: `False`
- has_references: `False`
- has_assets: `False`
