# advanced-evaluation

This skill should be used when the user asks to "implement LLM-as-judge", "compare model outputs", "create evaluation rubrics", "mitigate evaluation bias", or mentions direct scoring, pairwise comparison, position bias, evaluation pipelines, or automated quality assessment.

## Quick Facts
- id: `advanced-evaluation--675ccf6061`
- worth_using_score: `55/100`
- tags: `go, ci, rag, llm, eval`
- source: `agents_skills`
- source_path: `/home/wolvend/.agents/skills/muratcankoylan-advanced-evaluation/SKILL.md`

## Signal Summary
- has_description: `True`
- has_use_when: `False`
- has_workflow: `False`
- code_examples: `14`
- has_scripts: `True`
- has_references: `True`
- has_assets: `False`
