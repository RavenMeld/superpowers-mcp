# prompt-engineer

Use when designing prompts for LLMs, optimizing model performance, building evaluation frameworks, or implementing advanced prompting techniques like chain-of-thought, few-shot learning, or structured outputs.

## Quick Facts
- id: `prompt-engineer--4cc0b88689`
- worth_using_score: `55/100`
- tags: `testing, ci, llm, eval`
- source: `codex_skills`
- source_path: `/home/wolvend/.codex/skills/prompt-engineer/SKILL.md`

## Use When
- Designing prompts for new LLM applications
- Optimizing existing prompts for better accuracy or efficiency
- Implementing chain-of-thought or few-shot learning
- Creating system prompts with personas and guardrails
- Building structured output schemas (JSON mode, function calling)
- Developing prompt evaluation and testing frameworks
- Debugging inconsistent or poor-quality LLM outputs
- Migrating prompts between different models or providers

## Workflow / Steps
- **Understand requirements** - Define task, success criteria, constraints, edge cases
- **Design initial prompt** - Choose pattern (zero-shot, few-shot, CoT), write clear instructions
- **Test and evaluate** - Run diverse test cases, measure quality metrics
- **Iterate and optimize** - Refine based on failures, reduce tokens, improve reliability
- **Document and deploy** - Version prompts, document behavior, monitor production

## Signal Summary
- has_description: `True`
- has_use_when: `True`
- has_workflow: `True`
- code_examples: `0`
- has_scripts: `False`
- has_references: `True`
- has_assets: `False`
