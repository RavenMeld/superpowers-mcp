# fine-tuning-expert

Use when fine-tuning LLMs, training custom models, or optimizing model performance for specific tasks. Invoke for parameter-efficient methods, dataset preparation, or model adaptation.

## Quick Facts
- id: `fine-tuning-expert--a5d51e0ad0`
- worth_using_score: `55/100`
- tags: `ci`
- source: `codex_skills`
- source_path: `/home/wolvend/.codex/skills/fine-tuning-expert/SKILL.md`

## Use When
- Fine-tuning foundation models for specific tasks
- Implementing LoRA, QLoRA, or other PEFT methods
- Preparing and validating training datasets
- Optimizing hyperparameters for training
- Evaluating fine-tuned models
- Merging adapters and quantizing models
- Deploying fine-tuned models to production

## Workflow / Steps
- **Dataset preparation** - Collect, format, validate training data quality
- **Method selection** - Choose PEFT technique based on resources and task
- **Training** - Configure hyperparameters, monitor loss, prevent overfitting
- **Evaluation** - Benchmark against baselines, test edge cases
- **Deployment** - Merge/quantize model, optimize inference, serve

## Signal Summary
- has_description: `True`
- has_use_when: `True`
- has_workflow: `True`
- code_examples: `0`
- has_scripts: `False`
- has_references: `True`
- has_assets: `False`
